#Is there a covariate on top?
if(is.null(prevalence)) {
settings$gamma$mode <- "CTM" #without covariates has to be estimating the mean.
}
#Is there a covariate on the bottom?
if(is.null(content)) {
settings$kappa$interactions <- FALSE #can't have interactions without a covariate.
} else {
settings$kappa$LDAbeta <- FALSE #can't do LDA topics with a covariate
}
###
# process arguments in control
###
#Full List of legal extra arguments
legalargs <-  c("tau.maxit", "tau.tol",
"fixedintercept","kappa.mstepmaxit", "kappa.msteptol",
"kappa.enet", "nlambda", "lambda.min.ratio", "ic.k", "gamma.enet",
"gamma.ic.k",
"nits", "burnin", "alpha", "eta", "contrast",
"rp.s", "rp.p", "rp.d.group.size", "SpectralRP",
"recoverEG", "maxV", "gamma.maxits", "allow.neg.change",
"custom.beta", "tSNE_init.dims", "tSNE_perplexity")
if (length(control)) {
indx <- pmatch(names(control), legalargs, nomatch=0L)
if (any(indx==0L))
stop(gettextf("Argument %s not matched", names(control)[indx==0L]),
domain = NA)
fullnames <- legalargs[indx]
for(i in fullnames) {
if(i=="tau.maxit") settings$tau$maxit <- control[[i]]
if(i=="tau.tol") settings$tau$tol <- control[[i]]
if(i=="fixedintercept")settings$kappa$fixedintercept <- control[[i]]
if(i=="kappa.enet") settings$tau$enet <- control[[i]]
if(i=="kappa.mstepmaxit") settings$kappa$mstep$maxit <- control[[i]]
if(i=="kappa.msteptol") settings$kappa$mstep$tol <- control[[i]]
if(i=="nlambda") settings$tau$nlambda <- control[[i]]
if(i=="lambda.min.ratio") settings$tau$lambda.min.ratio <- control[[i]]
if(i=="ic.k") settings$tau$ic.k <- control[[i]]
if(i=="gamma.enet") settings$gamma$enet <- control[[i]]
if(i=="gamma.ic.k") settings$gamma$ic.k <- control[[i]]
if(i=="nits") settings$init$nits <- control[[i]]
if(i=="burnin") settings$init$burnin <- control[[i]]
if(i=="alpha") settings$init$alpha <- control[[i]]
if(i=="eta") settings$init$eta <- control[[i]]
if(i=="contrast") settings$kappa$contrast <- control[[i]]
if(i=="rp.s")  settings$init$s <- control[[i]]
if(i=="rp.p")  settings$init$p <- control[[i]]
if(i=="rp.d.group.size")  settings$init$d.group.size <- control[[i]]
if(i=="SpectralRP" && control[[i]]) settings$init$mode <- "SpectralRP" #override to allow spectral rp mode
if(i=="recoverEG" && !control[[i]]) settings$init$recoverEG <- control[[i]]
if(i=="maxV" && control[[i]]) {
settings$init$maxV <- control[[i]]
if(settings$init$maxV > V) stop("maxV cannot be larger than the vocabulary")
}
if(i=="tSNE_init.dims" && control[[i]]) settings$init$tSNE_init.dims <- control[[i]]
if(i=="tSNE_perplexity" && control[[i]]) settings$init$tSNE_perplexity <- control[[i]]
if(i=="gamma.maxits") settings$gamma$maxits <- control[[i]]
if(i=="allow.neg.change") settings$convergence$allow.neg.change <- control[[i]]
if(i=="custom.beta") {
if(settings$init$mode!="Custom") {
warning("Custom beta supplied, setting init argument to Custom.")
settings$init$mode <- "Custom"
}
settings$init$custom <- control[[i]]
}
}
}
###
# Process the Seed
###
if(is.null(settings$seed)) {
#if there is no seed, choose one and set it, recording for later
seed <- floor(runif(1)*1e7)
set.seed(seed)
settings$seed <- seed
} else {
#otherwise just use the provided seed.
set.seed(settings$seed)
}
settings$call <- Call
###
# Finally run the actual model
###
return(stm.control(documents, vocab, settings,model))
}
stm_from_dfm <- stm(gadarian_dfm, K = 3, prevalence = ~treatment + s(pid_rep),
data = docvars(gadarian_corpus))
Call
vocab
asSTMCorpus(documents, vocab, data)
asSTMCorpus()
asSTMCorpus
exit
quit
quit()
rm(list=ls())
gadarian_corpus <- corpus(gadarian, text_field = "open.ended.response")
gadarian_dfm <- gadarian_corpus |> tokens() |> tokens_remove(stopwords("english")) |> tokens_wordstem() |> dfm()
documents=gadarian_dfm; vocab = NULL; K = 3; prevalence = ~treatment + s(pid_rep); data = docvars(gadarian_corpus)
content=NULL;
rm(vocab)
content=NULL;
init.type=c("Spectral", "LDA", "Random", "Custom"); seed=NULL
max.em.its=500; emtol=1e-5
verbose=TRUE; reportevery=5
LDAbeta=TRUE; interactions=TRUE
ngroups=1; model=NULL
gamma.prior=c("Pooled", "L1"); sigma.prior=0
kappa.prior=c("L1", "Jeffreys"); control=list()
args <- asSTMCorpus(documents, vocab, data) # args <- asSTMCorpus(documents, data)
documents[["vocab"]]
jt <- quanteda::convert(documents, to = "stm", docvars = data)
jt[[vocab]]
jt[["vocab"]]
jt <- quanteda::convert(documents, to = "stm", docvars = data
)
d_tmp <- quanteda::convert(documents, to = "stm", docvars = data)
vocab = d_tmp[["vocab"]]
args <- asSTMCorpus(documents, vocab, data) # args <- asSTMCorpus(documents, data)
documents = d_tmp[["documents]]
"
]]
documents = d_tmp[["documents"]]
args <- asSTMCorpus(documents, vocab, data)
documents <- args$documents
vocab <- args$vocab
data <- args$data
N <- length(documents)
rm(list=ls())
library(readtext)
install.packages("readtext")
library(readtext)
blogs <- readtext("https://uclspp.github.io/datasets/data/poliblogs2008.zip")
data <- blogs
processed <- textProcessor(data$documents, metadata=data)
library(tm)
install.packages("tm")
library(tm)
processed <- textProcessor(data$documents, metadata=data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 15)
poliblogPrevFit <- stm(documents = out$documents, vocab = out$vocab, K = 20, prevalence =~ rating + s(day), max.em.its = 75, data = out$meta, init.type = "Spectral")
formula = 1:20 ~ rating + s(day); stmobj = poliblogPrevFit; metadata=out$meta
formula
uncertainty = "Global"; documents=NULL; nsims=25; prior=NULL
thetatype = "Global"
!is.null(metadata) & !is.data.frame(metadata)
termobj <- terms(formula, data=metadata)
attr(termobj, "response")
response <- as.character(formula)[2] #second object is the response in this cases
K <- eval(parse(text=response))
!(posint(K) && max(K)<=stmobj$settings$dim$K)
K
stmobj$settings$dim$K
max(K)
formula <- formula(paste(as.character(formula)[c(1,3)], collapse = " "))
termobj <- terms(formula, data=metadata)
mf <- model.frame(termobj, data=metadata)
xmat <- model.matrix(termobj,data=metadata)
varlist <- all.vars(termobj)
!is.null(metadata)
data <- metadata[, varlist, drop=FALSE]
metadata <- data
rm(data)
!is.null(prior)
qx <- qr(xmat)
qx
qx$rank < ncol(xmat)
storage <- vector(mode="list", length=length(K))
storage
nsims
thetatype
thetasims <- thetaPosterior(stmobj, nsims=1, type=thetatype, documents=documents)
thetasims <- do.call(rbind, thetasims)
thetasims
K
qr.lm(thetasims[,1], qx)
qr.lm <- function(y, qx) {
if(length(y)!=nrow(qx$qr)) {
#probably don't match because of a prior
if(length(y)!=(nrow(qx$qr)-ncol(qx$qr))) stop("number of covariate observations does not match number of docs")
#if it passes this check its the prior. thus
y <- c(y,rep(0, ncol(qx$qr)))
}
beta <- solve.qr(qx, y)
residuals <- qr.resid(qx,y)
fitted.values <- qr.fitted(qx,y)
df.residual <- length(fitted.values) - qx$rank
out <- list(coefficients=beta, residuals=residuals,
fitted.values=fitted.values,
df.residual=df.residual, rank=qx$rank, qr=qx)
out
}
qr.lm(thetasims[,k], qx)
k = 1
lm.mod <- qr.lm(thetasims[,k], qx)
lm.mod
summary.qr.lm <- function (object) {
z <- object
p <- z$rank
rdf <- z$df.residual
Qr <- object$qr
n <- nrow(Qr$qr)
p1 <- 1L:p
r <- z$residuals
f <- z$fitted.values
mss <- ifelse(attr(z$terms, "intercept"), sum((f - mean(f))^2), sum(f^2))
rss <- sum(r^2)
resvar <- rss/rdf
R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
se <- sqrt(diag(R) * resvar)
est <- z$coefficients[Qr$pivot[p1]]
sigma <- sqrt(resvar)
list(est=est, vcov=(sigma^2 * R))
}
summary.qr.lm(lm.mod)
jt <- summary.qr.lm(lm.mod)
str(jt)
is.vector(jt$est)
is.matrix(jt$est)
is.matrix(jt$vcov)
q('no'
)
library(knitr)
library(emoji)
library(dplyr)
knitr::opts_chunk$set(tidy=TRUE, prompt=TRUE, error=TRUE)
Mean_age2 <- 22  ## note: object names are case-sensitive
Mean_age2
all_ages <- c(22, 33, 44, 55)  # c() concatenates numbers together
all_ages
mean(all_ages)                 # calculate the mean
all_ed <- c("HS", "Col", "Grad Sch", "HS")
all_ed
important_data <- c("OSU", "R", "Group", 4)
important_data
test_scores <- c(88, 99, 110, 66, NA)  # NA is for missing values
mean_scores <- mean(test_scores)
mean_scores / 100
# test that we have a vector
is.vector(test_scores)  # returns another data type: TRUE or FALSE (called logical)
summary(test_scores)    # numerical summary (less helpful for strings)
length(test_scores)     # how many elements in the vector
is.na(test_scores)      # test if each element is NA
TRUE + TRUE + FALSE     # useful trick with logical objects (TRUE/FALSE)
n_missing <- sum(is.na(test_scores))
n_missing
test_scores[1]    # first element
test_scores[2]    # second element
1:3   # a vector of c(1, 2, 3)
# so what will test_scores[3:1] give us?
test_scores[3:1]  # returns 3rd element, then the 2nd, then the first
test_scores       # sanity check
test_scores[1]  <- NA # change the first element to NA
test_scores[1]
# create an index vector of TRUE & FALSE
index_missing_scores <- is.na(test_scores)
index_missing_scores
# attach these 2 vectors together as columns
cbind(index_missing_scores, test_scores)
test_scores[index_missing_scores]  #  access all of the indices with TRUE
# recode NA to -99
test_scores[index_missing_scores] <- -99
test_scores
# recode NA to -99
test_scores[index_missing_scores] <- -99
test_scores
which(test_scores == -99)
mtcars %>%
count(cyl)
mtcars %>%
n_distinct(cyl)
mtcars %>%
n_distinct()
mtcars %>%
select(cyl) %>%
n_distinct()
mtcars %>%
mean()
mtcars %>%
summarize(sum(cyl))
mtcars %>%
summarize(sum(cyl), sum(mpg))
sum(mtcars$cyl)
sum(mtcars$mgp)
sum(mtcars$mpg)
mtcars %>%
summarize(sum(cyl), mean(mpg))
mean(mtcars$mpg)
mtcars %>% summarize(IQR(cyl))
mtcars %>%
summarize(count(cyl), mean(mpg))
mtcars %>%
count(cyle)
mtcars %>%
count(cyl)
table(mtcars$cyl
)
mtcars %>%
summarize(mean(cyl), mean(mpg))
mtcars %>% groub_by(cyl, vs) %>% summarize(cyl_n = n())
mtcars %>% group_by(cyl, vs) %>% summarize(cyl_n = n())
mtcars %>% group_by(cyl, vs) %>% summarize(cyl_n = n(), avg = mean(cyl))
mtcars %>% group_by(cyl, vs) %>% summarize(cyl_n = n(), avg = mean(mpg))
mtcars
mtcars %>% filter(cyl l== 4)
mtcars %>% filter(cyl == 4)
mtcars %>% group_by(cyl) %>% summarize(d1 = mean(disp), d2 = sd(disp))
mtcars %>% summarize(d1 = mean(disp), d2 = sd(disp))
mtcars %>%
summarize(mean(cyl), sd(cyl), mean(mpg), sd(cyl))
mtcars %>%
summarize(mean(cyl), sd(cyl), mean(mpg), sd(mpg))
mtcars %>%
summarize(mean(cyl), sd(cyl), mean(mpg), col4 = sd(mpg))
mtcars %>%
summarize(quantile(cyl, c(1, 3), probs = c(.25, .75)))
mtcars %>%
summarize(quantile(cyl, c(1, 3)), probs = c(.25, .75)))
mtcars %>%
summarize(quantile(cyl, c(1, 3)), probs = c(.25, .75))
mtcars %>%
summarize(quantile(cyl, c(.25, .75)), probs = c(.25, .75))
mtcars %>%
summarize(quantile(cyl, c(.25, .75)))
mtcars %>%
summarize(quantile(mpg, c(.25, .75)))
mtcars
mtcars %>%
summarize(quantile(mpg, c(.25, .75)),
quantile(wt, c(.25, .75)))
mtcars %>%
summarize(qt_mpg = quantile(mpg, c(.25, .75)),
qt_wt = quantile(wt, c(.25, .75)))
x <- mtcars |> group_by(cyl) |> summarize(mean(hp))
x
mtcars |> group_by(cyl, vs) |> summarize(mu_hp = mean(hp), n = n())
x
x
names(x)
x |> ungroup()
mtcars |> group_by(cyl, vs) |> summarize(mu_hp = mean(hp), n = n())
x <- mtcars |> group_by(cyl) |> summarize(mean(hp))
x
x |> filter(cyl < 5)
x |> mutate(n = sum("mean(hp)"))
x <- mtcars |> group_by(cyl) |> summarize(mu = mean(hp))
x
x |> mutate(n = sum(mu))
x <- mtcars |> group_by(cyl, vs) |> summarize(mu = mean(hp))
x
x |> summarize(count(cyl))
x |> summarize(n(cyl))
x |> n(cyl)
x |> count(cyl)
x |> summarize(abs_min = min(mu))
x |> ungroup() |> summarize(abs_min = min(mu))
x
x |> sum(mu)
x |> mutate(grand_mu = mean(mu))
x |> count(cyl)
x <- mtcars |> group_by(cyl, vs) |> summarize(mu = mean(hp))
x
x <- mtcars |> group_by(cyl, vs) |> summarize(mu = mean(hp), n = n())
x
x |> mutate(grand_mean = weighted.mean(mu, n))
x <- mtcars |> group_by(cyl, vs) |> summarize(mu = mean(hp))
names(mtcars)
x
x
x |> mutate(mu100 = mu * 100)
x |> mutate(mu_min = min(mu))
mtcars |>
summarize(hp = mean(hp), sd_hp = sd(hp)
mtcars |>
summarize(hp = mean(hp), sd_hp = sd(hp))
mtcars |>
group_by(cyl, vs) |>
summarize(mu = mean(hp)) |>
mutate(min_mu = min(mu))
mtcars
mtcars |> group_by(cyl) |> mutate(mu_mgp = mean(mpg))
mtcars |> select(mpg, hp, cyl) |> group_by(cyl) |> mutate(mu_mgp = mean(mpg))
mtcars |> select(mpg, hp, cyl) |> group_by(cyl) |> mutate(mu_mgp = mean(mpg)) |> ungroup() |> mutate(grand_mu = mean(mpg))
mtcars(mtcars$mpg)
mean(mtcars$mpg)
letters
"g" %in% letters
c("1", "g") %in% letters
c("1", "g", "b") %in% letters
test_scores
letters
grep("Mazda", row.names(mtcars))
row.names(mtcars) == "Mazda"
raw.names(mtcars)
row.names(mtcars)
grepl("Mazda", row.names(mtcars))
library(knitr)
library(emoji)
library(dplyr)
knitr::opts_chunk$set(tidy=TRUE, prompt=TRUE, error=TRUE)
# only look at a few rows
mtcars %>%
select(mpg, cyl) %>%
slice(                                # look at certain rows
grepl("Mazda", row.names(mtcars)))   # (similar to filter)
names(mtcars)
head(mtcars)
library(knitr)
library(emoji)
library(tidyverse)
library(DT)
library(viridis)
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(tidy=FALSE, prompt=FALSE, error=TRUE,
fig.align = 'center', cache=TRUE)
data(mtcars)
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_scatter()
p2 <- ggplot(mtcars, aes(x = cyl, y = hp)) + geom_boxplot()
grid.arrange(p1, p2, nrow = 1)
library(gtable)
library(gridExtra)
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_scatter()
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point()
p2 <- ggplot(mtcars, aes(x = cyl, y = hp)) + geom_boxplot()
grid.arrange(p1, p2, nrow = 1)
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point()
p2 <- ggplot(mtcars, aes(x = factor(cyl), y = hp)) + geom_boxplot()
grid.arrange(p1, p2, nrow = 1)
lay <- rbind(c(1,1,1,2,3),
c(1,1,1,4,5),
c(6,7,8,9,9))
lay
?grid.arrange
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point()
p2 <- ggplot(mtcars, aes(x = factor(cyl), y = hp)) + geom_boxplot()
grid.arrange(p1, p2, nrow = 1)
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
ggrid.arrange(grobs = gg_list, nrow = 2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
grid.arrange(grobs = gg_list, nrow = 2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
grid.arrange(grobs = gg_list, nrow = 2, ncol = 2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
grid.arrange(grobs = gg_list, nrow = 2, ncol = 1:2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
gg_list
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
grid.arrange(grobs = gg_list, nrow = 1:3, ncol = 2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
grid.arrange(grobs = gg_list, nrow = 2, ncol = 2, widths = c(3, 3, 6),
top = "Figure X", bottom = "source: XXXX")
p1 <- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point()
p2 <- ggplot(mtcars, aes(x = factor(cyl), y = hp)) + geom_boxplot()
grid.arrange(p1, p2, nrow = 1)
gg_list <- list(p1, p2)
p3 <- ggplot(mtcars, aes(mpg, wt)) + facet_wrap( ~ cyl, nrow = 1)
gg_list[[3]] <- p3
# matrix for plot position
lay <- rbind(c(1,2),  # first row includes p1 & p2
c(3, 3)) # second row stretches p3 across both columns
grid.arrange(grobs = gg_list, layout_matrix = lay,
top = "Figure X", bottom = "source: XXXX")
ChickWeight
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight) + geom_line() + geom_smooth()
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight)) + geom_line() + geom_smooth()
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight)) + geom_point() + geom_smooth()
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight)) + geom_point() + geom_smooth() +
lab(Title = "Chick 1")
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight)) + geom_point() + geom_smooth() +
labs(Title = "Chick 1")
ChickWeight %>% filter(Chick == 1) %>%
ggplot(aes(Time, weight)) + geom_point() + geom_smooth() +
labs(title = "Chick 1")
max(ChickWeight$Chick)
str(ChickWeight)
lenght(table(ChickWeight$Chick))
length(table(ChickWeight$Chick))
n <- length(unique(ChickWeight$Chick))
n
gg_list <- list()
n <- length(unique(ChickWeight$Chick))
for (i in 1:n) {
gg_list[[i]] <- ChickWeight %>% filter(Chick == i) %>%
ggplot(aes(Time, weight)) + geom_point() + geom_smooth() +
labs(title = paste("Chick", i))
}
mg <- marrangeGrob(gg_list, nrow=1, ncol=1) #<<
ggsave(mg, "chicken_growth_trajectories.pdf")
ggsave("chicken_growth_trajectories.pdf", mg)
setwd("~/GitHub/R_Working_Group/ggplot2/2024_10_25")
